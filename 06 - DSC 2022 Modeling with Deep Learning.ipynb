{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6. Modeling with Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTENTS\n",
    "\n",
    "* <a href='00 - DSC 2022 Welcome and Logistics.ipynb#top'>**Section 0. Welcome and Logistics**</a> \n",
    "* <a href='01 - DSC 2022 Problem Definition.ipynb#top'>**Section 1. Problem Definition**</a> \n",
    "* <a href='02 - DSC 2022 Exploratory Data Analysis.ipynb#top'>**Section 2. Exploratory Data Analysis**</a> \n",
    "* <a href='03 - DSC 2022 Hypothesis testing.ipynb#top'>**Section 3. Hypothesis Testing**</a> \n",
    "* <a href='04 - DSC 2022 Feature Engineering.ipynb#top'>**Section 4. Feature Engineering**</a> \n",
    "* <a href='05 - DSC 2022 Modeling.ipynb#top'>**Section 5. Modeling**</a>\n",
    "* <a href='06 - DSC 2022 Modeling with Deep Learning.ipynb#top'>**Section 6. Modeling with Deep Learning**</a>\n",
    "  * [1. Model configuration](#configure)\n",
    "  * [2. Model training](#train)\n",
    "  * [3. Model inference](#inference)\n",
    "* <a href='07 - DSC 2022 Submission.ipynb#top'>**Section 7. Submission**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from feature_engineering import feature_engineering\n",
    "from evaluation import evaluation\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmg = pd.read_excel('cmg.xlsx', index_col = 'offeringId')\n",
    "X_train, X_test, y_train, y_test = feature_engineering(cmg, test_frac = 0.3, normalize = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='configure'></a>\n",
    "# 1. Model configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to configure the model, here we are implementing seq2seq model with teacher enforcing design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/seq2seq.png\" width=600 height=400 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 32),         4352        ['encoder_inputs[0][0]']         \n",
      "                                 (None, 32),                                                      \n",
      "                                 (None, 32)]                                                      \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 32),   4352        ['decoder_inputs[0][0]',         \n",
      "                                 (None, 32),                      'encoder_lstm[0][1]',           \n",
      "                                 (None, 32)]                      'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 1)     33          ['decoder_lstm[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,737\n",
      "Trainable params: 8,737\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_features = 1\n",
    "latent_dimension = 32\n",
    "\n",
    "# the encoder part \n",
    "encoder_inputs= Input(shape=(None, n_features), name = 'encoder_inputs')\n",
    "encoder_lstm=LSTM(latent_dimension, return_state=True, name = 'encoder_lstm') # we only want the output from the last cell \n",
    "_, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# the decoder part \n",
    "decoder_inputs = Input(shape=(None, n_features), name='decoder_inputs')\n",
    "decoder_lstm = LSTM(latent_dimension, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense = Dense(n_features, name='decoder_dense')\n",
    "decoder_outputs = TimeDistributed(decoder_dense)(decoder_outputs)\n",
    "\n",
    "# putting them together \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train'></a>\n",
    "## 2. Model training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after configuring our network, we shall go ahead and train our model. LSTM expects input data to be of 3D shape (# observation, timesteps, features). In our case, the number of timesteps is 15 since we are using data from 15 days prior to deal announcement; and the number of features if 1 since we are using just the stock price feature. Of course we could include more features, if they are not time series, then we could just replicate its values for # time steps. For the sake of a easy tutorial, we shall only work with the stock price feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_timesteps = 15\n",
    "post_timesteps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for the encoder part \n",
    "X_train_lstm = X_train.filter(like = 'pre').to_numpy().reshape(-1, pre_timesteps, 1)\n",
    "\n",
    "# prepare data for the decoder part \n",
    "y_train_input_lstm = pd.concat([X_train.filter(like = 'pre1_'), y_train.drop(columns = ['post180_Price_Normalized'])], axis = 1)\\\n",
    "                    .to_numpy()\\\n",
    "                    .reshape(-1, post_timesteps, 1)\n",
    "y_train_target_lstm = y_train.copy(deep = True)\\\n",
    "                        .to_numpy()\\\n",
    "                        .reshape(-1, post_timesteps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 51s, sys: 7min 16s, total: 30min 7s\n",
      "Wall time: 10min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2beaaf400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(optimizer = keras.optimizers.Adam(), loss = keras.losses.MeanSquaredError())\n",
    "model.fit([X_train_lstm, y_train_input_lstm], y_train_target_lstm, epochs = 500, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inference'></a>\n",
    "## 3. Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with a trained model, our next step is to use the model for inference. However, recall that during the training phase, we fed in true observations into the decoder part. However, in the inference phase, we no longer have the true observations. The solution to that is to predict output one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_inputs (InputLayer)    [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " h state (InputLayer)           [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " c state (InputLayer)           [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 32),   4352        ['decoder_inputs[0][0]',         \n",
      "                                 (None, 32),                      'h state[0][0]',                \n",
      "                                 (None, 32)]                      'c state[0][0]']                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, None, 1)     33          ['decoder_lstm[1][0]']           \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the decoder for inference \n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dimension,), name = 'h state')\n",
    "decoder_state_input_c = Input(shape=(latent_dimension,), name = 'c state')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = TimeDistributed(decoder_dense)(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_values = encoder_model.predict(input_seq.reshape(-1, pre_timesteps, 1), verbose = 0)\n",
    "    decoder_inputs = input_seq[-1].reshape(1,1,1)\n",
    "    result = []\n",
    "    \n",
    "    stop_condition = False\n",
    "    while len(result) < post_timesteps:\n",
    "        output, h, c = decoder_model.predict([decoder_inputs] + states_values, verbose = 0)\n",
    "        result.append(output.reshape(-1))\n",
    "        decoder_inputs = output.reshape(1, 1, 1)\n",
    "        states_values = [h, c]\n",
    "    return np.array(result).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2seq on train set:\n",
      " {'MSE': 9.335408849757176, 'ACC': 0.6357418800972996}\n",
      "CPU times: user 26min 2s, sys: 1min 4s, total: 27min 6s\n",
      "Wall time: 26min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_results = []\n",
    "for i in range(X_train_lstm.shape[0]):\n",
    "    train_results.append(decode_sequence(X_train_lstm[i]))\n",
    "print('Seq2seq on train set:\\n', evaluation(y_train, train_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2seq on test set:\n",
      " {'MSE': 23.133951086840046, 'ACC': 0.6321094793057369}\n",
      "CPU times: user 10min 52s, sys: 28 s, total: 11min 20s\n",
      "Wall time: 10min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test_lstm = np.array(X_test.filter(like = 'pre')).reshape(-1, pre_timesteps, 1)\n",
    "test_results = []\n",
    "for i in range(X_test_lstm.shape[0]):\n",
    "    test_results.append(decode_sequence(X_test_lstm[i]))\n",
    "print('Seq2seq on test set:\\n', evaluation(y_test, test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example given above, we showcased a very basic seq2seq design. Looks like we overfitted. It is now your turn to design, train and improve your own deep learning model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
